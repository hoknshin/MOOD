{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a957fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c570f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision==0.10.0\n",
      "  Downloading torchvision-0.10.0-cp36-cp36m-manylinux1_x86_64.whl (22.1 MB)\n",
      "     |████████████████████████████████| 22.1 MB 21.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from torchvision==0.10.0) (1.19.2)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (831.4 MB)\n",
      "     |████████████████████████████████| 831.4 MB 5.3 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: pillow>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from torchvision==0.10.0) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from torch==1.9.0->torchvision==0.10.0) (4.0.1)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from torch==1.9.0->torchvision==0.10.0) (0.8)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1\n",
      "    Uninstalling torch-1.7.1:\n",
      "      Successfully uninstalled torch-1.7.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.8.2\n",
      "    Uninstalling torchvision-0.8.2:\n",
      "      Successfully uninstalled torchvision-0.8.2\n",
      "Successfully installed torch-1.9.0 torchvision-0.10.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch==1.9.0\n",
    "!pip install torchvision==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f71657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building network of steps: \n",
      "[4, 4, 4, 4, 4] 20\n",
      " ********************** Block 1  **********************\n",
      "|\t\tinScales 3 outScales 3 inChannels 32 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 38 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 44 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 50 outChannels 6\t\t|\n",
      "\n",
      "224\n",
      " ********************** Block 2  **********************\n",
      "|\t\tinScales 3 outScales 3 inChannels 56 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 62 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 68 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 2 inChannels 74 outChannels 6\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 80, outChannels 40\t|\n",
      "\n",
      "160\n",
      " ********************** Block 3  **********************\n",
      "|\t\tinScales 2 outScales 2 inChannels 40 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 46 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 52 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 58 outChannels 6\t\t|\n",
      "\n",
      "256\n",
      " ********************** Block 4  **********************\n",
      "|\t\tinScales 2 outScales 2 inChannels 64 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 70 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 1 inChannels 76 outChannels 6\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 82, outChannels 41\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 41 outChannels 6\t\t|\n",
      "\n",
      "188\n",
      " ********************** Block 5  **********************\n",
      "|\t\tinScales 1 outScales 1 inChannels 47 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 53 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 59 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 65 outChannels 6\t\t|\n",
      "\n",
      "284\n",
      "Files already downloaded and verified\n",
      "*************************************\n",
      "False 782 157\n",
      "*************************************\n",
      "2822082\n",
      "calculating ood scores and complexity takes long time\n",
      "process  cifar10\n",
      "Files already downloaded and verified\n",
      "llf_complexity_array size: 157\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 168, in <module>\n",
      "    cal_complexity=False\n",
      "  File \"/home/ec2-user/SageMaker/MOOD/utils/MOOD.py\", line 303, in get_ood_score\n",
      "    print('mean ' + str(np.mean(llf_complexity_array)))\n",
      "  File \"<__array_function__ internals>\", line 6, in mean\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 3373, in mean\n",
      "    out=out, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/numpy/core/_methods.py\", line 160, in _mean\n",
      "    ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (16) at non-singleton dimension 0\n"
     ]
    }
   ],
   "source": [
    "#!python main.py -ms energy -ml 5 -ma 1 -mc png\n",
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127bc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fastai 1.0.61 nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494fc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gdown\n",
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608f8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complexity\tFlops\t\t\tmood.ipynb\t   README.md\n",
      "compressed.png\tmahalanobis_parameters\tmsd_args.py\t   trained_model\n",
      "data\t\tmain.py\t\t\tmsd_dataloader.py  utils\n",
      "figs\t\tmodels\t\t\t__pycache__\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09bb7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZB6wM9KPenTP-dzLutbMgn4wngDfatdf\n",
      "To: /home/ec2-user/SageMaker/MOOD/data/places365.zip\n",
      "100%|██████████| 8.83G/8.83G [04:24<00:00, 33.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'places365.zip'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1ZB6wM9KPenTP-dzLutbMgn4wngDfatdf'\n",
    "output = 'places365.zip'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "467dfb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building network of steps: \n",
      "[4, 4, 4, 4, 4] 20\n",
      " ********************** Block 1  **********************\n",
      "|\t\tinScales 3 outScales 3 inChannels 32 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 38 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 44 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 50 outChannels 6\t\t|\n",
      "\n",
      "224\n",
      " ********************** Block 2  **********************\n",
      "|\t\tinScales 3 outScales 3 inChannels 56 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 62 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 68 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 2 inChannels 74 outChannels 6\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 80, outChannels 40\t|\n",
      "\n",
      "160\n",
      " ********************** Block 3  **********************\n",
      "|\t\tinScales 2 outScales 2 inChannels 40 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 46 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 52 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 58 outChannels 6\t\t|\n",
      "\n",
      "256\n",
      " ********************** Block 4  **********************\n",
      "|\t\tinScales 2 outScales 2 inChannels 64 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 70 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 1 inChannels 76 outChannels 6\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 82, outChannels 41\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 41 outChannels 6\t\t|\n",
      "\n",
      "188\n",
      " ********************** Block 5  **********************\n",
      "|\t\tinScales 1 outScales 1 inChannels 47 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 53 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 59 outChannels 6\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 65 outChannels 6\t\t|\n",
      "\n",
      "284\n",
      "Files already downloaded and verified\n",
      "*************************************\n",
      "False 782 157\n",
      "*************************************\n",
      "2822082\n",
      "calculating ood scores and complexity takes long time\n",
      "process  cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from utils.dataloader import get_dataloader\n",
    "from utils.MOOD import get_ood_score, sample_estimator\n",
    "from utils.MOOD import auroc, fpr95\n",
    "#import argparse\n",
    "from msd_args import arg_parser\n",
    "import models\n",
    "from msd_dataloader import msd_get_dataloaders\n",
    "\n",
    "if 1: #load and test model\n",
    "\n",
    "    mood_args, _ = arg_parser.parse_known_args()\n",
    "    mood_args.grFactor = list(map(int, mood_args.grFactor.split('-')))\n",
    "    mood_args.bnFactor = list(map(int, mood_args.bnFactor.split('-')))\n",
    "    mood_args.nScales = len(mood_args.grFactor)\n",
    "    \n",
    "    if mood_args.use_valid:\n",
    "        mood_args.splits = ['train', 'val', 'test']\n",
    "    else:\n",
    "        mood_args.splits = ['train', 'val']\n",
    "    mood_args.data = mood_args.id\n",
    "    if mood_args.data == 'cifar10':\n",
    "        mood_args.num_classes = 10\n",
    "    elif mood_args.data == 'cifar100':\n",
    "        mood_args.num_classes = 100\n",
    "    else:\n",
    "        print('dataset not support!')\n",
    "    \n",
    "    model = getattr(models, mood_args.arch)(mood_args)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    train_loader, val_loader, test_loader = msd_get_dataloaders(mood_args)\n",
    "    print(\"*************************************\")\n",
    "    print(mood_args.use_valid, len(train_loader), len(val_loader))\n",
    "    print(\"*************************************\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(mood_args.file)['state_dict'])\n",
    "    print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "if mood_args.id == 'cifar10':\n",
    "    MEAN=[0.4914, 0.4824, 0.4467]\n",
    "    STD=[0.2471, 0.2435, 0.2616]\n",
    "    NM = [MEAN,STD]\n",
    "elif mood_args.id == 'cifar100':\n",
    "    MEAN=[0.5071, 0.4867, 0.4408]\n",
    "    STD=[0.2675, 0.2565, 0.2761]\n",
    "    NM = [MEAN,STD]\n",
    "else:\n",
    "    print('wrong indistribution dataset! use cifar10 or cifar100!')\n",
    "    \n",
    "normalizer = transforms.Normalize(mean=MEAN, std=STD)\n",
    "print('calculating ood scores and complexity takes long time')\n",
    "print('process ',mood_args.id)\n",
    "\n",
    "dataloader = get_dataloader(mood_args.id, normalizer, mood_args.bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44f86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "432030ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process  mnist\n",
      "size 10000\n",
      "min 142.0\n",
      "max 705.0\n",
      "mean 456.8935\n",
      "process  dtd\n",
      "size 5640\n",
      "min 98.0\n",
      "max 3113.0\n",
      "mean 2165.7916666666665\n",
      "process  lsunR\n",
      "size 10000\n",
      "min 1233.0\n",
      "max 3159.0\n",
      "mean 2694.7017\n",
      "********** auroc result  cifar10  with  energy_llf  **********\n",
      "                         auroc                  fpr95    \n",
      "OOD dataset      exit@last    MOOD      exit@last    MOOD\n",
      "mnist             0.7869     0.6753      0.7332     0.8875\n",
      "dtd               0.3234     0.3029      0.9782     0.9846\n",
      "lsunR             0.5000     0.4993      0.9500     0.9470\n",
      "average           0.5368     0.4925      0.8871     0.9397\n"
     ]
    }
   ],
   "source": [
    "i_score, i_adjusted_score, i_complexity = get_ood_score(data_name=mood_args.id,\n",
    "                           model=model,\n",
    "                           L=mood_args.layer,\n",
    "                           dataloader=dataloader,\n",
    "                           score_type=mood_args.score,\n",
    "                           threshold=mood_args.threshold,\n",
    "                           NM=NM,\n",
    "                           adjusted_mode=0,   \n",
    "                           mean=None,\n",
    "                           cal_complexity=False\n",
    "                           )\n",
    "mean=[]\n",
    "for i in range(mood_args.layer):\n",
    "    mean.append( np.mean(i_score[i]) )\n",
    "\n",
    "i_score, i_adjusted_score, i_complexity = get_ood_score(data_name=mood_args.id,\n",
    "                           model=model,\n",
    "                           L=mood_args.layer,\n",
    "                           dataloader=dataloader,\n",
    "                           score_type=mood_args.score,\n",
    "                           threshold=mood_args.threshold,\n",
    "                           NM=NM,\n",
    "                           adjusted_mode=mood_args.adjusted,\n",
    "                           mean=mean,\n",
    "                           cal_complexity=False\n",
    "                           )\n",
    "auroc_base = []\n",
    "fpr95_base = []\n",
    "auroc_mood = []\n",
    "fpr95_mood = []\n",
    "auroc_for_barplot = []\n",
    "complexity_for_arplot = []\n",
    "for o_name in mood_args.od:\n",
    "    print('process ',o_name)\n",
    "    dataloader = get_dataloader(o_name, normalizer, mood_args.bs)\n",
    "    o_score, o_adjusted_score, o_complexity = get_ood_score(data_name=o_name,\n",
    "                           model=model,\n",
    "                           L=mood_args.layer,\n",
    "                           dataloader=dataloader,\n",
    "                           score_type=mood_args.score,\n",
    "                           threshold=mood_args.threshold,\n",
    "                           NM=NM,\n",
    "                           adjusted_mode=mood_args.adjusted,\n",
    "                           mean=mean,\n",
    "                           cal_complexity=False\n",
    "                           )\n",
    "    print('size ' + str(o_complexity.size))\n",
    "    print('min ' + str(np.min(o_complexity)))\n",
    "    print('max ' + str(np.max(o_complexity)))\n",
    "    print('mean ' + str(np.mean(o_complexity)))\n",
    "\n",
    "    auroc_base.append(auroc(i_score[-1], o_score[-1]))\n",
    "    fpr95_base.append(fpr95(i_score[-1], o_score[-1]))\n",
    "    auroc_mood.append(auroc(i_adjusted_score, o_adjusted_score))\n",
    "    fpr95_mood.append(fpr95(i_adjusted_score, o_adjusted_score))\n",
    "    auroc_for_barplot.append([auroc(i_score[i], o_score[i]) for i in range(mood_args.layer)])\n",
    "    complexity_for_arplot.append(o_complexity)\n",
    "\n",
    "print('********** auroc result ',mood_args.id,' with ',mood_args.score,' **********')\n",
    "print('                         auroc                  fpr95    ')\n",
    "print('OOD dataset      exit@last    MOOD      exit@last    MOOD')\n",
    "for i in range(len(mood_args.od)):\n",
    "    data_name=mood_args.od[i]\n",
    "    data_name = data_name + ' '*(17-len(data_name))\n",
    "    print(data_name,\"%.4f\"%auroc_base[i],'   ',\"%.4f\"%auroc_mood[i],'    ',\"%.4f\"%fpr95_base[i],'   ',\"%.4f\"%fpr95_mood[i])\n",
    "data_name = 'average'\n",
    "data_name = data_name + ' '*(17-len(data_name))\n",
    "print(data_name,\"%.4f\"%np.mean(auroc_base),'   ',\"%.4f\"%np.mean(auroc_mood),'    ',\"%.4f\"%np.mean(fpr95_base),'   ',\"%.4f\"%np.mean(fpr95_mood))\n",
    "\n",
    "\n",
    "if mood_args.score == 'energy' and mood_args.adjusted == 1 :\n",
    "    flops = np.array([26621540, 51598536, 68873004, 88417936, 105102580])\n",
    "    auroc_score = np.array(auroc_for_barplot)\n",
    "    S=20\n",
    "    selected_datasets = mood_args.od\n",
    "    selected_score = np.zeros_like(auroc_score)\n",
    "    for k, complexity in enumerate(complexity_for_arplot):\n",
    "        for i in range(mood_args.layer):\n",
    "            index = (mood_args.threshold[i]<complexity) * (complexity<=mood_args.threshold[i+1])\n",
    "            selected_score[k,i] = np.sum(index)/complexity.shape[0]\n",
    "    \n",
    "    Flops = np.zeros([len(mood_args.od)])\n",
    "    for i in range(len(mood_args.od)):\n",
    "        Flops[i] = np.sum(selected_score[i,:]*flops)\n",
    "    Flops2 = np.ones([len(mood_args.od)])*flops[-1]\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import pandas\n",
    "    df = pandas.DataFrame({\n",
    "    'dataset': selected_datasets,\n",
    "    'Exit@1': selected_score[:,0],\n",
    "    'Exit@2': selected_score[:,1],\n",
    "    'Exit@3': selected_score[:,2],\n",
    "    'Exit@4': selected_score[:,3],\n",
    "    'Exit@5': selected_score[:,4],\n",
    "    })\n",
    "    fig, ax = plt.subplots(figsize=(30,5.5))\n",
    "    tidy = df.melt(id_vars='dataset').rename(columns={\"dataset\": \"Dataset\",\n",
    "                                                      \"variable\": \"Method\",\n",
    "                                                      \"value\": \"AUROC\"})\n",
    "    sns.barplot(x='Dataset', y='AUROC', hue='Method', data=tidy, ax=ax, palette=['#d9ece0','#a8e9dd','#8bd6f3','#508fed','#544cbd','#909090'])\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=S)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=S)\n",
    "    plt.xlabel('Dataset', fontsize=S)\n",
    "    plt.ylabel('Exit Distribution', fontsize=S)\n",
    "    plt.ylim(0,1)\n",
    "    ax.legend(bbox_to_anchor=(1.14, 0.90), fontsize=S)\n",
    "    \n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(selected_datasets, Flops, '--', label = 'MOOD',marker='x', linewidth=2.5)\n",
    "    ax2.plot(selected_datasets, Flops2, '--', label = 'Exit@5',marker='x', linewidth=2.5)\n",
    "\n",
    "    ax2.set_ylabel(\"Computational Cost(Flops)\", fontsize=S)\n",
    "    plt.setp(ax2.get_yticklabels(), fontsize=S)\n",
    "    ax2.yaxis.get_offset_text().set_fontsize(S-4)\n",
    "    ax2.legend(bbox_to_anchor=(1.14, 0.30), fontsize=S)\n",
    "\n",
    "    fig.savefig(\"Flops.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3bcfa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "1233.0\n",
      "3159.0\n",
      "2694.7017\n"
     ]
    }
   ],
   "source": [
    "print(o_complexity.size)\n",
    "print(np.min(o_complexity))\n",
    "print(np.max(o_complexity))\n",
    "print(np.mean(o_complexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b53d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
